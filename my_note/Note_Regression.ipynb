{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1 :\n",
    "#### find a model.\n",
    "\n",
    "It's a set of function.\n",
    "\n",
    "e.g. $Y = wX + b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2:\n",
    "#### Goodness of Function\n",
    "\n",
    "use **Loss Function** to compute **error**.\n",
    "\n",
    "A Loss Function is: $L(f^*) = \\sum (\\hat{y}^n - f(x^n)) ^ 2 $ or more popular is $f_{RMS} =  \\sqrt{\\frac{\\sum (\\hat{y}^n - f(x^n)) ^ 2}{N}} $\n",
    "\n",
    "$f^*$ is a specific function come from your model.\n",
    "\n",
    "$\\hat{y}$ is the real data for $x$\n",
    "\n",
    "obviously, A best function may have small average error\n",
    "\n",
    "#### regularization\n",
    "\n",
    "One technique is used to control the over-fitting\n",
    "\n",
    "modify **Loss Function** to :\n",
    "\n",
    "$$\n",
    "L(f^*) = \\sum (\\hat{y}^n - f(x^n)) ^ 2 + \\lambda\\sum(w_n)^2\n",
    "$$\n",
    "\n",
    "less $\\lambda \\sum(w_n)^2 $ means smoother functoin\n",
    "\n",
    "$\\lambda$ governs the **relative importance** of the **regularization term** compared with the **SQ error term**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3:\n",
    "#### gradien descent\n",
    "\n",
    "how to adjust your coefficient of your function:\n",
    "\n",
    "   compute derivative, which is (Gradient) \\begin{bmatrix}\n",
    "                                           \\frac{\\partial L}{\\partial w} \\\\\n",
    "                                            \\frac{\\partial L}{\\partial b}\n",
    "                                            \\end{bmatrix}\n",
    "   \n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial w} = \\sum 2 (\\hat{y}^n - f(x^n))(-x^n)\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "    \\frac{\\partial L}{\\partial b} = \\sum 2 (\\hat{y}^n - f(x^n))(-1)\n",
    "   $$\n",
    "   \n",
    "   for function has more than one parameter\n",
    "   \n",
    "   compute partial derivative separatly\n",
    "   \n",
    "   \n",
    "#### learning rate\n",
    "\n",
    "Adaptive learning rate\n",
    "\n",
    "**larger learning rate means faster learning speed**\n",
    "    \n",
    "* $\\eta$ is initial learning rate\n",
    "\n",
    "* $\\eta^{t}$ is t times learning rate \n",
    "\n",
    "* vanilia Gradient Descent:\n",
    "    * learning rate = $\\eta^t = \\frac{\\eta}{\\sqrt {t+1}}$ \n",
    "\n",
    "* Adagrad:\n",
    "    \n",
    "    * learning rate = $\\frac{\\eta^t}{\\sigma^t}$\n",
    "    \n",
    "    * $\\sigma^t$ = root mean sqaure of previous derivatives of parameter w\n",
    "    \n",
    "    * $\\frac{\\eta^t}{\\sigma^t}$ = $\\frac{\\eta}{\\sum (g^i)^2}$ (g is gradient)\n",
    "\n",
    "    \n",
    "#### stochastic Gradient Descent\n",
    "\n",
    "Update parameter after seeing each example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>bias and variance\n",
    "\n",
    "reference: \n",
    "* https://revisionmaths.com/advanced-level-maths-revision/statistics/expectation-and-variance\n",
    "* https://www.mathsisfun.com/data/standard-deviation.html\n",
    "\n",
    "real mean of $x$  : $\\mu$ \n",
    "\n",
    "real variance of $x$ : $\\sigma^2$ \n",
    "\n",
    "### estimate $\\mu$\n",
    "\n",
    "$mean = \\frac{1}{N} \\displaystyle\\sum_n x^n \\neq \\mu $ (unless has infinite sample)\n",
    "\n",
    "$E[mean] = E[\\frac{1}{N}\\displaystyle\\sum_n x^n]  = \\frac{1}{N} \\displaystyle\\sum_n E[x^n] = \\mu$\n",
    "\n",
    "\n",
    "### estimate $\\sigma^2$\n",
    "\n",
    "$var[f] = E [(f(x) - E[f(x)])^2] = E[f(x)^2] - E[f(x)]^2$\n",
    "\n",
    "$var[f] = s^2 = \\frac{1}{N} \\sum (x^n - m) ^ 2$ (when N is the population)\n",
    "\n",
    "$var[f] = s^2 = \\frac{1}{N-1} \\sum (x^n - m) ^ 2$ (when N is a sample)\n",
    "\n",
    "$var[mean] = \\frac{1}{N} \\sigma^2 \\neq \\sigma^2 $\n",
    "\n",
    "how to deal with bias?\n",
    "\n",
    "* redesign model\n",
    "\n",
    "how to deal with variance?\n",
    " \n",
    "* collect more data\n",
    "\n",
    "* regularizatoin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
